INFO: Starting training:
        Epochs:          5
        Batch size:      1
        Learning rate:   1e-05
        Training size:   283
        Validation size: 31
        Checkpoints:     True
        Device:          cuda
        Images scaling:  0.5
        Mixed Precision: False

c:\Users\AMI-DEEP3\Desktop\younguk\Pytorch-UNet-master\Pytorch-UNet-master\train.py:92: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)
Epoch 1/5:   0%|                                                                                                                                              | 0/283 [01:08<?, ?img/s]
Traceback (most recent call last):
  File "c:\Users\AMI-DEEP3\Desktop\younguk\Pytorch-UNet-master\Pytorch-UNet-master\train.py", line 237, in <module>
    train_model(
  File "c:\Users\AMI-DEEP3\Desktop\younguk\Pytorch-UNet-master\Pytorch-UNet-master\train.py", line 133, in train_model
    F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
