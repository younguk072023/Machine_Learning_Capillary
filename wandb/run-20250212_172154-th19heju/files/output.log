INFO: Starting training:
        Epochs:          5
        Batch size:      1
        Learning rate:   1e-05
        Training size:   283
        Validation size: 31
        Checkpoints:     True
        Device:          cuda
        Images scaling:  0.5
        Mixed Precision: False

c:\Users\AMI-DEEP3\Desktop\younguk\Pytorch-UNet-master (1)\Pytorch-UNet-master\train.py:80: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)
Epoch 1/5:   0%|                                                                                                                                              | 0/283 [01:07<?, ?img/s]
Traceback (most recent call last):
  File "c:\Users\AMI-DEEP3\Desktop\younguk\Pytorch-UNet-master (1)\Pytorch-UNet-master\train.py", line 213, in <module>
    train_model(
  File "c:\Users\AMI-DEEP3\Desktop\younguk\Pytorch-UNet-master (1)\Pytorch-UNet-master\train.py", line 108, in train_model
    F.softmax(masks_pred, dim=1).float(),
  File "c:\Users\AMI-DEEP3\anaconda3\envs\younguks\lib\site-packages\torch\nn\functional.py", line 2140, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
