import torch
import torchvision.models as models             #torchvisionì€ ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬ ë° ResNet ëª¨ë¸ ì œê³µ
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision import datasets
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt                 
import numpy as np
import seaborn as sns                           #í˜¼ë™ í–‰ë ¬
from sklearn.metrics import confusion_matrix
import math
from torch.optim.lr_scheduler import ReduceLROnPlateau

# í•œê¸€ í°íŠ¸ ì„¤ì • (í•œê¸€ ê¹¨ì§ ë°©ì§€)
plt.rcParams['font.family'] = "Malgun Gothic"


train_transform = transforms.Compose([
    transforms.Resize((128, 128)),  
    transforms.ToTensor(),  # ğŸ”¹ ë°ì´í„°ë¥¼ PyTorch Tensorë¡œ ë³€í™˜
    transforms.Normalize(mean=[0.5], std=[0.5])  # ğŸ”¹ ì •ê·œí™” ì ìš©
])

test_transform = transforms.Compose([
    transforms.Resize((128, 128)),  
    transforms.ToTensor(),  
    transforms.Normalize(mean=[0.5], std=[0.5])  
])


# ë°ì´í„°ì…‹ ë¡œë“œ
train_dataset = datasets.ImageFolder(root=r"C:\Users\AMI-DEEP3\Desktop\younguk\data\train",transform=train_transform)
test_dataset = datasets.ImageFolder(root=r"C:\Users\AMI-DEEP3\Desktop\younguk\data\test",transform=test_transform)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)


# ë°ì´í„° ê°œìˆ˜ í™•ì¸
print(f"âœ… Train ë°ì´í„° ê°œìˆ˜: {len(train_dataset)}")
print(f"âœ… Test ë°ì´í„° ê°œìˆ˜: {len(test_dataset)}")

# âœ… ResNet50 ëª¨ë¸ ì •ì˜ (BatchNorm + Dropout ì¶”ê°€)
model = models.resnet50(pretrained=True)        #pretrained=TrueëŠ” ì´ë¯¸ ImageNetë°ì´í„°ë„·ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜´
num_classes = 2     #ì •ìƒ, ë¹„ì •ìƒ í´ë˜ìŠ¤
model.fc = nn.Sequential(
    nn.Dropout(0.5),  
    nn.BatchNorm1d(model.fc.in_features),           #í•™ìŠµ ì•ˆì •í™”í™”
    nn.Linear(model.fc.in_features, num_classes)    #ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)


# âœ… ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì • (L2 Regularization í¬í•¨)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)                       #weight decayëŠ” ê³¼ì í•© ë°©ì§€
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)      #verbose=TrueëŠ” í•™ìŠµë¥  ë³€ê²½ë  ë•Œ ë¡œê·¸ ì¶œë ¥.

# âœ… ì†ì‹¤ ì €ì¥ ë¦¬ìŠ¤íŠ¸
loss_history = []


num_epochs = 100

# ì¡°ê¸°ì¢…ë£Œ 
early_stopping_patience = 10  
best_loss = float("inf")        #ì§€ê¸ˆê¹Œì§€ í•™ìŠµí•œ ì¤‘ ê°€ì¥ ë‚®ì€ ì†ì‹¤ê°’ì„ ì €ì¥
early_stop_count = 0            #ì†ì‹¤ ê°’ì´ ê°œì„ ë˜ì§€ ì•Šì€ íšŸìˆ˜ ì €ì¥í›„ ì¹´ìš´íŠ¸ ì¦ê°€ ex patienceë¥¼ ë„˜ì–´ê°€ë§ˆë…€ í•™ìŠµ ì¢…ë£Œ

print("\n ********************í•™ìŠµ ì‹œì‘*****************")

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()                                   #ê¸°ìš¸ê¸° ì´ˆê¸°í™”
        outputs = model(images)                             
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()                             #í˜„ì¬ ë°°ì¹˜ì—ì„œ ê³„ì‚°ëœ loss ê°’ì„ running_lossì— ë”í•¨.

    epoch_loss = running_loss / len(train_loader)
    loss_history.append(epoch_loss)                             
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}")

    # í•™ìŠµë¥  ê°ì†Œ ì ìš©
    scheduler.step(epoch_loss)                                  #ì†ì‹¤ ê°’ì´ ì¤„ì–´ë“¤ì§€ ì•Šìœ¼ë©´ í•™ìŠµë¥ ì„ ë‚®ì¶¤


    # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ì²´í¬
    if epoch_loss < best_loss:
        best_loss = epoch_loss
        early_stop_count = 0  
    else:
        early_stop_count += 1
        if early_stop_count >= early_stopping_patience:
            print(f"ğŸš€ ì¡°ê¸° ì¢…ë£Œ: {epoch+1} Epochì—ì„œ í•™ìŠµ ì¤‘ë‹¨!")
            break


# âœ… ì†ì‹¤ ê·¸ë˜í”„ ì‹œê°í™”
plt.figure(figsize=(5, 8))
plt.plot(range(1, len(loss_history) + 1), loss_history, marker='o', linestyle='-', color='tab:blue', label='Loss')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Restnet50 Training Loss")
plt.legend()
plt.show()

# í…ŒìŠ¤íŠ¸ í‰ê°€
model.eval()

correct = 0     #ëª¨ë¸ì´ ë§ì¶˜ ê°œìˆ˜
total = 0
all_preds = []
all_labels = []
test_images = []

# ì •ìƒ / ë¹„ì •ìƒ ê°ê° 10ê°œì”© ì €ì¥
normal_count, abnormal_count = 0, 0

with torch.no_grad():           #ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™” : í‰ê°€í• ë–„ëŠ” ë©”ëª¨ë¦¬ì ˆì•½
    for images, labels in test_loader:                              # test_loaderë§Œ ì‚¬ìš©!
        images, labels = images.to(device), labels.to(device)   
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)

        correct += (predicted == labels).sum().item()
        total += labels.size(0)

        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

        # ì •ìƒ / ë¹„ì •ìƒ ê°ê° 10ê°œì”© ì €ì¥
        for i in range(len(images)):
            label = labels[i].cpu().numpy()
            if (label == 0 and normal_count < 10) or (label == 1 and abnormal_count < 10):
                test_images.append((images[i].cpu().numpy(), label, predicted[i].cpu().numpy()))
                if label == 0:
                    normal_count += 1
                else:
                    abnormal_count += 1

# í…ŒìŠ¤íŠ¸ ì •í™•ë„ ì¶œë ¥
accuracy = (correct / total) * 100
print(f"âœ… ResNet50 í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.2f}%")

# Confusion Matrix ì‹œê°í™”
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["ì •ìƒ", "ë¹„ì •ìƒ"], yticklabels=["ì •ìƒ", "ë¹„ì •ìƒ"])
plt.xlabel("ì˜ˆì¸¡ê°’")
plt.ylabel("ì‹¤ì œê°’")
plt.title("ResNet50 Confusion Matrix")
plt.show()

# ì •ê·œí™” í•´ì œ í•¨ìˆ˜ (ì´ë¯¸ì§€ë¥¼ ì›ë˜ ê°’ìœ¼ë¡œ ë³µì›)
def denormalize(img):
    img = img * 0.5 + 0.5  
    img = np.clip(img, 0, 1)  
    return img

# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²°ê³¼ ì‹œê°í™” (20ê°œì”© í˜ì´ì§€ë„¤ì´ì…˜)
class_names = ["ì •ìƒ", "ë¹„ì •ìƒ"]
images_per_page = 25  
num_pages = math.ceil(len(test_images) / images_per_page)

for page in range(num_pages):
    start_idx = page * images_per_page
    end_idx = min(start_idx + images_per_page, len(test_images))

    fig, axes = plt.subplots(5, 5, figsize=(13, 13))  
    fig.suptitle(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²°ê³¼ (í˜ì´ì§€ {page + 1}/{num_pages})", fontsize=16)

    for i, ax in enumerate(axes.flat):
        img_idx = start_idx + i
        if img_idx < len(test_images):
            image, true_label, pred_label = test_images[img_idx]
            image = denormalize(np.transpose(image, (1, 2, 0)))  

            ax.imshow(image)
            ax.set_title(f"ì •ë‹µ: {class_names[true_label]}\nì˜ˆì¸¡: {class_names[pred_label]}", fontsize=10,
                         color="green" if true_label == pred_label else "red")
            ax.axis("off")
        else:
            ax.axis("off")  

    plt.show()
